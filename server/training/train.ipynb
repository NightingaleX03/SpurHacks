{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8176ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "device = \"cuda\" \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=device, torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d7e3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PersonalCode\\SpurHacks\\server\\venv\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "c:\\PersonalCode\\SpurHacks\\server\\venv\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,277,952 || all params: 1,237,092,352 || trainable%: 0.1033\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=12,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42931290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "data = load_jsonl(\"../resources/alpaca_formatted_data.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9473bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_prompt = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a helpful and knowledgeable assistant specialized in generating clear and accurate \"\n",
    "            \"architecture diagrams using Mermaid.js markdown syntax. When given a user's request, your task is to:\\n\\n\"\n",
    "            \"- Understand the user's description, which may be detailed or vague.\\n\"\n",
    "            \"- Suggest one or more appropriate architecture styles, such as monolith, microservices, serverless, or hybrid.\\n\"\n",
    "            \"- Respect any design constraints mentioned, such as specific cloud providers (AWS, Azure, GCP), frameworks, or technologies.\\n\"\n",
    "            \"- Generate valid Mermaid.js markdown code representing the requested architecture or diagrams.\\n\"\n",
    "            \"- Support multiple diagrams if the user asks for alternatives or different styles.\\n\"\n",
    "            \"- Provide diagrams that are clean, well-labeled, and easy to read.\\n\"\n",
    "            \"- Optionally suggest real-time edits or improvements when prompted.\\n\"\n",
    "            \"- Avoid adding any commentary or explanations; respond only with Mermaid markdown code blocks unless otherwise requested.\\n\"\n",
    "            \"- Always wrap your Mermaid diagrams inside triple backticks with the word `mermaid` to ensure proper formatting.\\n\\n\"\n",
    "            \"Example user request: \\\"Design a microservices architecture on AWS for a social media app.\\\"\\n\\n\"\n",
    "            \"Your response should be:\\n\\n\"\n",
    "            \"```mermaid\\n\"\n",
    "            \"graph TD\\n\"\n",
    "            \"    User[User] --> API[API Gateway]\\n\"\n",
    "            \"    API --> Auth[Auth Service (Lambda)]\\n\"\n",
    "            \"    API --> Post[Post Service (ECS)]\\n\"\n",
    "            \"    API --> Media[Media Service (S3)]\\n\"\n",
    "            \"    Auth --> DynamoDB[DynamoDB]\\n\"\n",
    "            \"    Post --> RDS[RDS]\\n\"\n",
    "            \"```\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Design a microservices architecture on AWS for a social media app.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": (\n",
    "            \"```mermaid\\n\"\n",
    "            \"graph TD\\n\"\n",
    "            \"    User[User] --> API[API Gateway]\\n\"\n",
    "            \"    API --> Auth[Auth Service (Lambda)]\\n\"\n",
    "            \"    API --> Post[Post Service (ECS)]\\n\"\n",
    "            \"    API --> Media[Media Service (S3)]\\n\"\n",
    "            \"    Auth --> DynamoDB[DynamoDB]\\n\"\n",
    "            \"    Post --> RDS[RDS]\\n\"\n",
    "            \"```\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "target_response = training_prompt[-1][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de88dc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1697ba8157c949b6b662aaa65242b687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/294 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    for instruction in examples[\"instruction\"]:\n",
    "        prompt = training_prompt[0][\"content\"] + \"\\n\\n\"\n",
    "        prompt += training_prompt[1][\"content\"] + \"\\n\\n\"\n",
    "        prompt += instruction + \"\\n\\n\"\n",
    "\n",
    "        inputs.append(prompt)\n",
    "\n",
    "    for response in examples[\"response\"]:\n",
    "        labels.append(response)\n",
    "\n",
    "    # Tokenize inputs\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, truncation=True, max_length=512, padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    # Tokenize labels (target response)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels_tokenized = tokenizer(\n",
    "            labels, truncation=True, max_length=512, padding=\"max_length\"\n",
    "        )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels_tokenized[\"input_ids\"]\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_data = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f325d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "input_ids: [128000, 2675, 527, 264, 11190, 323, 42066, 18328, 28175, 304, 24038, 2867, 323, 13687, 18112, 47287, 1701, 8930, 46342, 2927, 51594, 20047, 13, 3277, 2728, 264, 1217, 596, 1715, 11, 701, 3465, 374, 311, 1473, 12, 71994, 279, 1217, 596, 4096, 11, 902, 1253, 387, 11944, 477, 40146, 627, 12, 328, 3884, 832, 477, 810, 8475, 18112, 9404, 11, 1778, 439, 1647, 48218, 11, 8162, 13069, 11, 3622, 1752, 11, 477, 26038, 627, 12, 78138, 904, 2955, 17413, 9932, 11, 1778, 439, 3230, 9624, 12850, 320, 37236, 11, 35219, 11, 480, 7269, 705, 49125, 11, 477, 14645, 627, 12, 20400, 2764, 8930, 46342, 2927, 51594, 2082, 14393, 279, 11472, 18112, 477, 47287, 627, 12, 9365, 5361, 47287, 422, 279, 1217, 17501, 369, 27548, 477, 2204, 9404, 627, 12, 40665, 47287, 430, 527, 4335, 11, 1664, 2922, 23121, 11, 323, 4228, 311, 1373, 627, 12, 97295, 4284, 1972, 7394, 51944, 477, 18637, 994, 29746, 627, 12, 35106, 7999, 904, 31710, 477, 41941, 26, 6013, 1193, 449, 8930, 46342, 51594, 2082, 10215, 7389, 6062, 11472, 627, 12, 24119, 15411, 701, 8930, 46342, 47287, 4871, 24657, 1203, 36178, 449, 279, 3492, 1595, 1195, 46342, 63, 311, 6106, 6300, 37666, 382, 13617, 1217, 1715, 25, 330, 21103, 264, 8162, 13069, 18112, 389, 24124, 369, 264, 3674, 3772, 917, 2266, 7927, 2077, 1288, 387, 1473, 74694, 1195, 46342, 198, 4539, 28816, 198, 262, 2724, 58, 1502, 60, 3929, 5446, 58, 7227, 40478, 933, 262, 5446, 3929, 7517, 58, 5197, 5475, 320, 59366, 5680, 262, 5446, 3929, 3962, 58, 4226, 5475, 320, 36, 6546, 5680, 262, 5446, 3929, 7972, 58, 12950, 5475, 320, 50, 18, 5680, 262, 7517, 3929, 72913, 3590, 66020, 86708, 3590, 933, 262, 3962, 3929, 432, 6061, 46087, 6061, 933, 14196, 19884, 21103, 264, 8162, 13069, 18112, 389, 24124, 369, 264, 3674, 3772, 917, 382, 47825, 21673, 3788, 1129, 2185, 23192, 21854, 25081, 21854, 2726, 29239, 47117, 36317, 1908, 29344, 287, 44658, 12, 43331, 20653, 17158, 14, 31842, 443, 12538, 3941, 5429, 738, 342, 4922, 12880, 861, 284, 3075, 77785, 2358, 53303, 25, 330, 70, 4922, 12880, 14235, 498, 89752, 25, 330, 70, 4922, 12880, 26915, 1, 6547, 738, 636, 12880, 3915, 21265, 284, 1754, 591, 314, 1095, 342, 4922, 8001, 20455, 284, 36566, 1095, 8443, 284, 2246, 40927, 26, 1095, 73527, 284, 8443, 5402, 62164, 5146, 369, 320, 1169, 602, 284, 220, 15, 26, 602, 366, 73527, 1996, 26, 602, 2516, 314, 1095, 18385, 1982, 284, 73527, 1004, 948, 7105, 67477, 1237, 422, 320, 292, 1982, 58, 15, 948, 10893, 368, 624, 330, 70, 4922, 20455, 909, 314, 342, 4922, 8001, 20455, 284, 18385, 1982, 58, 16, 948, 10893, 2178, 335, 335, 471, 342, 4922, 8001, 20455, 335, 422, 34760, 2252, 32124, 21326, 493, 85694, 33207, 598, 73543, 79764, 1393, 1772, 32124, 21326, 493, 85694, 33207, 598, 14, 3874, 6226, 767, 374, 26915, 3720, 284, 636, 12880, 3915, 21265, 368, 624, 342, 4922, 12880, 861, 920, 9272, 949, 837, 551, 905, 26, 2246, 8751, 446, 2664, 1865, 32417, 446, 695, 22592, 15331, 498, 374, 26915, 3720, 1237, 335, 734, 86782, 3511, 14139, 368, 314]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "labels: [128000, 567, 73534, 77349, 11688, 320, 52, 2735, 8, 36361, 82, 271, 52, 2735, 47287, 527, 9302, 44713, 1511, 304, 3241, 15009, 311, 14158, 11, 51187, 11, 9429, 11, 323, 2246, 279, 36136, 315, 264, 3241, 1887, 13, 2435, 1520, 304, 8830, 11, 30829, 11, 323, 20958, 6485, 6067, 382, 14711, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001]\n",
      "\n",
      "Example 1:\n",
      "input_ids: [128000, 2675, 527, 264, 11190, 323, 42066, 18328, 28175, 304, 24038, 2867, 323, 13687, 18112, 47287, 1701, 8930, 46342, 2927, 51594, 20047, 13, 3277, 2728, 264, 1217, 596, 1715, 11, 701, 3465, 374, 311, 1473, 12, 71994, 279, 1217, 596, 4096, 11, 902, 1253, 387, 11944, 477, 40146, 627, 12, 328, 3884, 832, 477, 810, 8475, 18112, 9404, 11, 1778, 439, 1647, 48218, 11, 8162, 13069, 11, 3622, 1752, 11, 477, 26038, 627, 12, 78138, 904, 2955, 17413, 9932, 11, 1778, 439, 3230, 9624, 12850, 320, 37236, 11, 35219, 11, 480, 7269, 705, 49125, 11, 477, 14645, 627, 12, 20400, 2764, 8930, 46342, 2927, 51594, 2082, 14393, 279, 11472, 18112, 477, 47287, 627, 12, 9365, 5361, 47287, 422, 279, 1217, 17501, 369, 27548, 477, 2204, 9404, 627, 12, 40665, 47287, 430, 527, 4335, 11, 1664, 2922, 23121, 11, 323, 4228, 311, 1373, 627, 12, 97295, 4284, 1972, 7394, 51944, 477, 18637, 994, 29746, 627, 12, 35106, 7999, 904, 31710, 477, 41941, 26, 6013, 1193, 449, 8930, 46342, 51594, 2082, 10215, 7389, 6062, 11472, 627, 12, 24119, 15411, 701, 8930, 46342, 47287, 4871, 24657, 1203, 36178, 449, 279, 3492, 1595, 1195, 46342, 63, 311, 6106, 6300, 37666, 382, 13617, 1217, 1715, 25, 330, 21103, 264, 8162, 13069, 18112, 389, 24124, 369, 264, 3674, 3772, 917, 2266, 7927, 2077, 1288, 387, 1473, 74694, 1195, 46342, 198, 4539, 28816, 198, 262, 2724, 58, 1502, 60, 3929, 5446, 58, 7227, 40478, 933, 262, 5446, 3929, 7517, 58, 5197, 5475, 320, 59366, 5680, 262, 5446, 3929, 3962, 58, 4226, 5475, 320, 36, 6546, 5680, 262, 5446, 3929, 7972, 58, 12950, 5475, 320, 50, 18, 5680, 262, 7517, 3929, 72913, 3590, 66020, 86708, 3590, 933, 262, 3962, 3929, 432, 6061, 46087, 6061, 933, 14196, 19884, 21103, 264, 8162, 13069, 18112, 389, 24124, 369, 264, 3674, 3772, 917, 382, 3112, 14677, 6168, 40004, 1628, 14677, 6168, 40004, 1628, 14677, 6150, 21579, 6150, 21579, 6150, 21579, 28082, 49175, 45635, 28082, 49175, 45635, 28082, 49175, 45635, 48778, 73738, 311, 11050, 1991, 29022, 51310, 3648, 398, 5034, 10880, 0, 18532, 53704, 24686, 65349, 24124, 36542, 2520, 22938, 71502, 62434, 220, 4645, 25, 423, 7934, 612, 744, 7127, 1061, 10170, 16543, 6826, 71568, 56360, 11050, 320, 20944, 8, 14934, 40004, 17005, 320, 43, 6674, 8, 1061, 71150, 612, 86859, 304, 13325, 2520, 20783, 29337, 74435, 17026, 1061, 10170, 320, 20944, 8, 1061, 29696, 612, 41425, 6354, 491, 393, 4535, 320, 34, 1044, 14, 71568, 8, 18532, 79150, 39524, 320, 20944, 8, 9619, 14619, 11050, 449, 3676, 612, 6146, 12438, 320, 20944, 8, 9619, 14619, 11050, 1061, 10170, 6826, 2460, 48778, 48778, 48778, 423, 7934, 311, 11050, 1991, 29022, 51310, 3648, 398, 5034, 10880, 0, 18532, 53704, 24686, 65349, 24124, 36542, 2520, 22938, 71502, 62434, 220, 4645, 25, 423, 7934, 612, 744, 7127, 1061, 10170, 16543, 6826, 71568, 56360, 11050, 320, 20944, 8, 14934, 40004, 17005, 320, 43, 6674, 8, 1061, 71150, 612, 86859, 304, 13325, 2520, 20783, 29337, 74435, 17026, 1061, 10170, 320, 20944, 8, 1061, 29696, 612, 41425, 6354, 491, 393, 4535, 320, 34, 1044, 14, 71568, 8, 18532, 79150, 39524, 320]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "labels: [128000, 567, 46551, 323, 32406, 36361, 82, 271, 2028, 2246, 50729, 5370, 13861, 4595, 11, 872, 5829, 11, 23692, 11, 323, 9886, 5528, 11, 8104, 21760, 389, 1495, 6108, 7526, 1093, 8930, 46342, 323, 18317, 52, 2735, 382, 45464, 14711, 220, 16, 13, 29971, 36361, 82, 271, 334, 10614, 68063, 362, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"input_ids:\", tokenized_data[i][\"input_ids\"])\n",
    "    print(\"attention_mask:\", tokenized_data[i][\"attention_mask\"])\n",
    "    print(\"labels:\", tokenized_data[i][\"labels\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "077541ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=\"./lora-llama-3.2-1b\",\n",
    "    per_device_train_batch_size=1,\n",
    "    learning_rate=1e-3,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=1,\n",
    "    max_steps=1000,\n",
    ")\n",
    "\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_data,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_trainer.train()\n",
    "\n",
    "peft_trainer.model.save_pretrained(\"./my_finetuned_model\")\n",
    "tokenizer.save_pretrained(\"./my_finetuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6621ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
    "model = PeftModel.from_pretrained(base_model, './my_finetuned_model')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87283c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
